{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import lisa\n",
    "lisa = importlib.reload(lisa)\n",
    "\n",
    "from lisa.core.data_interface import DataInterface,PACKAGE_PATH\n",
    "from lisa.core.genome_tools import Genome\n",
    "from lisa.core.utils import indices_list_to_sparse_array\n",
    "from lisa.core import data_interface\n",
    "data_interface = importlib.reload(data_interface)\n",
    "\n",
    "import configparser\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_conversion/lisa1_data.ini']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species = 'hg38'\n",
    "\n",
    "old_data_path = os.path.join('data_conversion','old_data',species) \n",
    "\n",
    "v1_config = configparser.ConfigParser()\n",
    "v1_config.read(os.path.join('data_conversion', 'lisa1_data.ini'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1:\n",
    "\n",
    "Go to NCBI Table browser and select the UCSC refGene table for mm10, output all fields. Download this table as \"mm10.refseq\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2:\n",
    "\n",
    "Download old LISA data:\n",
    "\n",
    "```\n",
    "wget -c http://lisa.cistrome.org/cistromedb_data/lisa_v1.2_hg38.tar.gz\n",
    "```\n",
    "and unpack into ./old_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-01-06 16:38:19--  http://lisa.cistrome.org/cistromedb_data/lisa_v1.2_hg38.tar.gz\n",
      "Resolving lisa.cistrome.org (lisa.cistrome.org)... 155.52.218.90\n",
      "Connecting to lisa.cistrome.org (lisa.cistrome.org)|155.52.218.90|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 46000911950 (43G) [application/x-gzip]\n",
      "Saving to: ‘lisa_v1.2_hg38.tar.gz’\n",
      "\n",
      "lisa_v1.2_hg38.tar.   0%[                    ]       0  --.-KB/s               ^C\n",
      "tar: Error opening archive: truncated gzip input\n"
     ]
    }
   ],
   "source": [
    "!wget -c http://lisa.cistrome.org/cistromedb_data/lisa_v1.2_hg38.tar.gz\n",
    "\n",
    "!mv lisa_v1.2_hg38.tar.gz data_conversion/old_data\n",
    "\n",
    "!tar -xvf data_conversion/old_data/lisa_v1.2_hg38.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tad_info = pd.read_csv(v1_config.get(species, 'tad_info').format(prefix = old_data_path),\n",
    "                        sep = '\\t')\n",
    "tad_info['tad_group'] = tad_info.k4me3_order_cluster.astype(str) + '-' + tad_info.tad_order_cluster.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = pd.read_csv(os.path.join(PACKAGE_PATH, 'genomes',species + '.genome'), sep = '\\t', header = None)\n",
    "genome.columns = ['chrom','length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = pd.read_csv(os.path.join('data_conversion', 'old_data', species + '.refseq'), sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = genes.merge(tad_info[['geneName','tad_group']], left_on='name2',\n",
    "            right_on='geneName', how = 'left').fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes.merge(genome['chrom'], on = 'chrom', how = 'right')\\\n",
    "    [['name','chrom','strand','txStart','txEnd','exonStarts','exonEnds','name2', 'tad_group']]\\\n",
    "    .to_csv(os.path.join(PACKAGE_PATH,'genomes',species + '.refseq'), header = None, index = None, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "refseq=os.path.join(PACKAGE_PATH,'genomes',species + '.refseq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NM_000299\tchr1\t+\t201283451\t201332993\t201283451,201293941,201313165,201316552,201317571,201318617,201319815,201320266,201321977,201323012,201324427,201324940,201325753,201328761,201330073,\t201283904,201294045,201313560,201316697,201317779,201318795,201319878,201320381,201322133,201323189,201324581,201325127,201325838,201328868,201332993,\tPKP1\t1-6\r\n",
      "NM_001276351\tchr1\t-\t67092165\t67134970\t67092165,67095234,67096251,67115351,67125751,67127165,67131141,67134929,\t67093604,67095421,67096321,67115464,67125909,67127257,67131227,67134970,\tC1orf141\t1-5\r\n"
     ]
    }
   ],
   "source": [
    "!head -n2 $refseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hg38.genome hg38.refseq mm10.genome mm10.refseq\r\n"
     ]
    }
   ],
   "source": [
    "!ls $PACKAGE_PATH/genomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3:\n",
    "\n",
    "Instantiate a data inferface using the new genome and genes, then use it to generate RP maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading gene info ...\n"
     ]
    }
   ],
   "source": [
    "data = data_interface.DataInterface(species, window_size=1000, make_new=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_rp_map, enhanced_rp_map = data.build_binned_rp_map('basic',10000), data.build_binned_rp_map('enhanced', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.add_rp_map('basic_10K', basic_rp_map)\n",
    "data.add_rp_map('enhanced_10K', enhanced_rp_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40772, 3088281)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_rp_map.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: \n",
    "\n",
    "Load the old genome format and map to the new bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_genome = Genome.from_file(v1_config.get(species,'chrom_len').format(prefix = old_data_path),\n",
    "                             window_size=1000, _sort=False)\n",
    "\n",
    "genome_map = old_genome.map_genomes(data.genome)\n",
    "genome_map = np.array(genome_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in old metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(v1_config.get('basics','meta').format(prefix = old_data_path), encoding='latin', sep = '\\t')\\\n",
    "    .set_index('id')\n",
    "metadata.index = metadata.index.astype(str)\n",
    "motif_meta = pd.read_csv(v1_config.get('basics','motif').format(prefix = old_data_path), encoding='latin', sep = '\\t')\\\n",
    "    .set_index('id')\n",
    "motif_meta['factor'] = motif_meta.symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5:\n",
    "\n",
    "Transfer accessibility arrays to new format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_accessibility_data(technology, old_data_path):\n",
    "    \n",
    "    with h5.File(v1_config.get(species, technology + '_count').format(prefix = old_data_path), 'r') as old_data:\n",
    "        dataset_ids = np.array(old_data['IDs'][...]).astype(str)\n",
    "        acc_matrix = np.array(old_data['OrderCount'][...])\n",
    "        \n",
    "    return acc_matrix, dataset_ids\n",
    "\n",
    "def add_accessibility_matrix(data, technology, acc_matrix, dataset_ids,*, rp_maps, rp_map_styles, metadata,\n",
    "                            reads_range, bin_map):\n",
    "    \n",
    "    headers = data.get_metadata_headers(technology)\n",
    "    \n",
    "    for i, dataset_id in enumerate(dataset_ids):\n",
    "        \n",
    "        dataset_id = str(dataset_id).split('_')[0]\n",
    "        \n",
    "        sample_metadata = metadata.loc[dataset_id, headers + ['qc']].to_dict()\n",
    "        \n",
    "        sample_acc = np.array(acc_matrix[:, i]).reshape(-1)\n",
    "        \n",
    "        if int(sample_metadata['qc']) == 1 and (reads_range[0] <= sample_acc.sum() <= reads_range[1]):\n",
    "\n",
    "            sample_acc = data.project_array(sample_acc, bin_map, len(data.genome))\n",
    "\n",
    "            data.add_profile_data(technology, str(dataset_id), sample_acc, rp_maps, \n",
    "                                      rp_map_styles, **sample_metadata)\n",
    "            \n",
    "        print('\\rProcessed {} samples'.format(str(i + 1)), end = '')\n",
    "            \n",
    "def convert_accessibility(*,data,technology, old_data_path, bin_map, \n",
    "                          rp_maps, rp_map_styles, metadata, reads_range):\n",
    "    \n",
    "    acc_matrix, dataset_ids = load_accessibility_data(technology, old_data_path)\n",
    "    \n",
    "    print('Loaded data!')\n",
    "\n",
    "    add_accessibility_matrix(data, technology, acc_matrix, dataset_ids, \n",
    "                         rp_maps=rp_maps, rp_map_styles=rp_map_styles,\n",
    "                        metadata = metadata, reads_range = reads_range, bin_map = bin_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data!\n",
      "Processed 1106 samples"
     ]
    }
   ],
   "source": [
    "accessibility_kwargs = dict(\n",
    "    data = data,\n",
    "    old_data_path=old_data_path,\n",
    "    bin_map=genome_map, rp_maps = [basic_rp_map, enhanced_rp_map], rp_map_styles = ['basic_10K','enhanced_10K'],\n",
    "    metadata = metadata\n",
    ")\n",
    "\n",
    "convert_accessibility(technology='DNase', **accessibility_kwargs, reads_range = (75000, 160000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_accessibility(technology = 'H3K27ac',**accessibility_kwargs, reads_range = (130000, 170000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6:\n",
    "\n",
    "Transfer factor binding to new genome scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_genome_100bp = Genome.from_file(v1_config.get(species,'chrom_len').format(prefix = old_data_path),\n",
    "                             window_size=100, _sort=False)\n",
    "\n",
    "hits_binmap = np.array(old_genome_100bp.map_genomes(data.genome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tf_matrix(config_key, old_data_path, num_bins, metadata, offset = 0, skip_qc = False):\n",
    "\n",
    "    with h5.File(v1_config.get(species, config_key)\\\n",
    "                 .format(prefix = old_data_path), 'r') as tf_hits:\n",
    "\n",
    "        num_samples = len(list(tf_hits.keys()))\n",
    "        \n",
    "        indices, dataset_ids = [],[]\n",
    "        \n",
    "        for sample in tf_hits.keys():\n",
    "            \n",
    "            if not sample == 'IDs' and not sample == 'TFs':\n",
    "                \n",
    "                try:\n",
    "                    sample_metadata = metadata.loc[sample]\n",
    "                \n",
    "                    if skip_qc or sample_metadata.qc == 1:\n",
    "                        \n",
    "                        factor_name = sample_metadata.factor.replace('/', '-').replace('_','-')\n",
    "\n",
    "                        peaks = tf_hits[sample][...]\n",
    "                        peaks = peaks - offset\n",
    "                        \n",
    "                        indices.append(peaks)\n",
    "                        dataset_ids.append(sample)\n",
    "                        \n",
    "                except OSError:\n",
    "                    print('\\n\\tError saving data for sample {}, factor: {}'\\\n",
    "                          .format(str(sample), sample_metadata.factor))\n",
    "                except KeyError:\n",
    "                    print('\\n\\tError: No metadata for sample {}'.format(str(sample)))\n",
    "                    \n",
    "        tf_matrix = indices_list_to_sparse_array(indices, num_bins)\n",
    "        \n",
    "        return tf_matrix, dataset_ids\n",
    "\n",
    "def write_tf_matrix(data, technology, dataset_ids, tf_matrix, metadata):\n",
    "    \n",
    "    tf_matrix = tf_matrix.T.tocsr()\n",
    "    \n",
    "    for i, dataset_id in enumerate(dataset_ids):\n",
    "        dataset_id = str(dataset_id)\n",
    "        save_indices = tf_matrix[i, :].indices\n",
    "        sample_metadata = metadata.loc[dataset_id, data.get_metadata_headers(technology)].to_dict()\n",
    "        data.add_binding_data(technology, dataset_id, save_indices, **sample_metadata)\n",
    "        \n",
    "def convert_tf_binding(*, data, technology, config_key, old_data_path, original_num_bins, hits_binmap,\n",
    "                metadata, offset = 0, skip_qc = False):\n",
    "    \n",
    "    tf_matrix, dataset_ids = load_tf_matrix(config_key, old_data_path, original_num_bins, \n",
    "                                        metadata, offset = offset, skip_qc = skip_qc)\n",
    "    \n",
    "    projected_tf_matrix = data.project_sparse_matrix(tf_matrix.T, hits_binmap, len(data.genome))\n",
    "    \n",
    "    write_tf_matrix(data, technology, dataset_ids, projected_tf_matrix, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChIP-seq data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_tf_binding(data = data, technology = 'ChIP-seq', config_key = 'tf_chipseq', old_data_path = old_data_path, \n",
    "                  original_num_bins = len(old_genome_100bp), metadata = metadata, offset = 1, skip_qc = False,\n",
    "                  hits_binmap = hits_binmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motif data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_tf_binding(data = data, technology = 'Motifs', config_key = 'genome_100bp_motif_index99', old_data_path = old_data_path,\n",
    "                original_num_bins = len(old_genome_100bp), metadata = motif_meta, offset = 0, skip_qc = True,\n",
    "                hits_binmap = hits_binmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 100bp hits data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_hitbin_data = data_interface.DataInterface(species, window_size=100, make_new=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_fine_binmap = np.array(old_genome_100bp.map_genomes(fine_hitbin_data.genome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_tf_binding(data = fine_hitbin_data, technology = 'ChIP-seq', config_key = 'tf_chipseq', old_data_path = old_data_path, \n",
    "                  original_num_bins = len(old_genome_100bp), metadata = metadata, offset = 1, skip_qc = False,\n",
    "                  hits_binmap = hits_fine_binmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_tf_binding(data = fine_hitbin_data, technology = 'Motifs', config_key = 'genome_100bp_motif_index99', old_data_path = old_data_path,\n",
    "                original_num_bins = len(old_genome_100bp), metadata = motif_meta, offset = 0, skip_qc = True,\n",
    "                hits_binmap = hits_fine_binmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lisa_2.1_testing",
   "language": "python",
   "name": "lisa_2.1_testing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
