{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import lisa\n",
    "lisa = importlib.reload(lisa)\n",
    "\n",
    "from lisa.core.data_interface import DataInterface,PACKAGE_PATH\n",
    "from lisa.core.genome_tools import Genome\n",
    "from lisa.core.utils import indices_list_to_sparse_array\n",
    "from lisa.core import data_interface\n",
    "data_interface = importlib.reload(data_interface)\n",
    "\n",
    "import configparser\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = 'mm10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_conversion/lisa1_data.ini']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_data_path = os.path.join('data_conversion','old_data',species) \n",
    "\n",
    "v1_config = configparser.ConfigParser()\n",
    "v1_config.read(os.path.join('data_conversion', 'lisa1_data.ini'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1:\n",
    "\n",
    "Go to NCBI Table browser and select the UCSC refGene table for mm10, output all fields. Download this table as \"mm10.refseq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mhg38\u001b[m\u001b[m                  lisa_v1.2_hg38.tar.gz \u001b[1m\u001b[36mmm10\u001b[m\u001b[m\r\n",
      "hg38.refseq           lisa_v1.2_mm10.tar.gz mm10.refseq\r\n"
     ]
    }
   ],
   "source": [
    "!ls data_conversion/old_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tad_info = pd.read_csv(v1_config.get(species, 'tad_info').format(prefix = old_data_path),\n",
    "                        sep = '\\t')\n",
    "tad_info['tad_group'] = tad_info.k4me3_order_cluster.astype(str) + '-' + tad_info.tad_order_cluster.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = pd.read_csv(os.path.join(PACKAGE_PATH, 'genomes',species + '.genome'), sep = '\\t', header = None)\n",
    "genome.columns = ['chrom','length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = pd.read_csv(os.path.join('data_conversion', 'old_data', species + '.refseq'), sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = genes.merge(tad_info[['geneName','tad_group']], left_on='name2',\n",
    "            right_on='geneName', how = 'left').fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes.merge(genome['chrom'], on = 'chrom', how = 'right')\\\n",
    "    [['name','chrom','strand','txStart','txEnd','exonStarts','exonEnds','name2', 'tad_group']]\\\n",
    "    .to_csv(os.path.join(PACKAGE_PATH,'genomes',species + '.refseq'), header = None, index = None, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "refseq=os.path.join(PACKAGE_PATH,'genomes',species + '.refseq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2:\n",
    "\n",
    "Download old LISA data:\n",
    "\n",
    "```\n",
    "wget -c http://lisa.cistrome.org/cistromedb_data/lisa_v1.2_mm10.tar.gz\n",
    "```\n",
    "and unpack into ./old_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3:\n",
    "\n",
    "Instantiate a data inferface using the new genome and genes, then use it to generate RP maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading gene info ...\n"
     ]
    }
   ],
   "source": [
    "data = data_interface.DataInterface('mm10', window_size=1000, make_new=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_rp_map, enhanced_rp_map = data.build_binned_rp_map('basic',10000), data.build_binned_rp_map('enhanced', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.add_rp_map('basic_10K', basic_rp_map)\n",
    "data.add_rp_map('enhanced_10K', enhanced_rp_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: \n",
    "\n",
    "Load the old genome format and map to the new bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_genome = Genome.from_file(v1_config.get(species,'chrom_len').format(prefix = old_data_path),\n",
    "                             window_size=1000, _sort=False)\n",
    "\n",
    "genome_map = old_genome.map_genomes(data.genome)\n",
    "genome_map = np.array(genome_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in old metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(v1_config.get('basics','meta').format(prefix = old_data_path), encoding='latin', sep = '\\t')\\\n",
    "    .set_index('id')\n",
    "metadata.index = metadata.index.astype(str)\n",
    "motif_meta = pd.read_csv(v1_config.get('basics','motif').format(prefix = old_data_path), encoding='latin', sep = '\\t')\\\n",
    "    .set_index('id')\n",
    "motif_meta['factor'] = motif_meta.symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5:\n",
    "\n",
    "Transfer accessibility arrays to new format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_accessibility_data(technology, old_data_path):\n",
    "    \n",
    "    with h5.File(v1_config.get(species, technology + '_count').format(prefix = old_data_path), 'r') as old_data:\n",
    "        dataset_ids = np.array(old_data['IDs'][...]).astype(str)\n",
    "        acc_matrix = np.array(old_data['OrderCount'][...])\n",
    "        \n",
    "    return acc_matrix, dataset_ids\n",
    "\n",
    "def add_accessibility_matrix(data, technology, acc_matrix, dataset_ids,*, rp_maps, rp_map_styles, metadata,\n",
    "                            reads_range):\n",
    "    \n",
    "    headers = data.get_metadata_headers(technology)\n",
    "    \n",
    "    for i, dataset_id in enumerate(dataset_ids):\n",
    "\n",
    "        dataset_id = str(dataset_id).split('_')[0]\n",
    "        sample_metadata = metadata.loc[dataset_id, headers + ['qc']].to_dict()\n",
    "\n",
    "        sample_acc = np.array(acc_matrix[:, i]).reshape(-1)\n",
    "\n",
    "        if int(sample_metadata['qc']) == 1 and (reads_range[0] <= sample_acc.sum() <= reads_range[1]):\n",
    "            data.add_profile_data(technology, str(dataset_id), sample_acc, rp_maps, \n",
    "                                      rp_map_styles, **sample_metadata)\n",
    "            \n",
    "def convert_accessibility(*,data,technology, old_data_path, bin_map, \n",
    "                          rp_maps, rp_map_styles, metadata, reads_range):\n",
    "    \n",
    "    acc_matrix, dataset_ids = load_accessibility_data(technology, old_data_path)\n",
    "\n",
    "    projected_acc_matrix = np.vstack([\n",
    "        data.project_array(r, bin_map, len(data.genome))\n",
    "        for r in acc_matrix.T\n",
    "    ]).T\n",
    "    \n",
    "    \n",
    "    add_accessibility_matrix(data, technology, projected_acc_matrix, dataset_ids, \n",
    "                         rp_maps=rp_maps, rp_map_styles=rp_map_styles,\n",
    "                        metadata = metadata, reads_range = reads_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "accessibility_kwargs = dict(\n",
    "    data = data,\n",
    "    old_data_path=old_data_path,\n",
    "    bin_map=genome_map, rp_maps = [basic_rp_map, enhanced_rp_map], rp_map_styles = ['basic_10K','enhanced_10K'],\n",
    "    metadata = metadata\n",
    ")\n",
    "\n",
    "convert_accessibility(technology='DNase', **accessibility_kwargs, reads_range = (75000, 160000))\n",
    "\n",
    "convert_accessibility(technology='H3K27ac', **accessibility_kwargs, reads_range = (130000, 160000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6:\n",
    "\n",
    "Transfer factor binding to new genome scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_genome_100bp = Genome.from_file(v1_config.get(species,'chrom_len').format(prefix = old_data_path),\n",
    "                             window_size=100, _sort=False)\n",
    "\n",
    "hits_binmap = np.array(old_genome_100bp.map_genomes(data.genome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tf_matrix(config_key, old_data_path, num_bins, metadata, offset = 0, skip_qc = False):\n",
    "\n",
    "    with h5.File(v1_config.get(species, config_key)\\\n",
    "                 .format(prefix = old_data_path), 'r') as tf_hits:\n",
    "\n",
    "        num_samples = len(list(tf_hits.keys()))\n",
    "        \n",
    "        indices, dataset_ids = [],[]\n",
    "        \n",
    "        for sample in tf_hits.keys():\n",
    "            \n",
    "            if not sample == 'IDs' and not sample == 'TFs':\n",
    "                \n",
    "                try:\n",
    "                    sample_metadata = metadata.loc[sample]\n",
    "                \n",
    "                    if skip_qc or sample_metadata.qc == 1:\n",
    "                        \n",
    "                        factor_name = sample_metadata.factor.replace('/', '-').replace('_','-')\n",
    "\n",
    "                        peaks = tf_hits[sample][...]\n",
    "                        peaks = peaks - offset\n",
    "                        \n",
    "                        indices.append(peaks)\n",
    "                        dataset_ids.append(sample)\n",
    "                        \n",
    "                except OSError:\n",
    "                    print('\\n\\tError saving data for sample {}, factor: {}'\\\n",
    "                          .format(str(sample), sample_metadata.factor))\n",
    "                except KeyError:\n",
    "                    print('\\n\\tError: No metadata for sample {}'.format(str(sample)))\n",
    "                    \n",
    "        tf_matrix = indices_list_to_sparse_array(indices, num_bins)\n",
    "        \n",
    "        return tf_matrix, dataset_ids\n",
    "\n",
    "def write_tf_matrix(data, technology, dataset_ids, tf_matrix, metadata):\n",
    "    \n",
    "    tf_matrix = tf_matrix.T.tocsr()\n",
    "    \n",
    "    for i, dataset_id in enumerate(dataset_ids):\n",
    "        dataset_id = str(dataset_id)\n",
    "        save_indices = tf_matrix[i, :].indices\n",
    "        sample_metadata = metadata.loc[dataset_id, data.get_metadata_headers(technology)].to_dict()\n",
    "        data.add_binding_data(technology, dataset_id, save_indices, **sample_metadata)\n",
    "        \n",
    "def convert_tf_binding(*, data, technology, config_key, old_data_path, original_num_bins, hits_binmap,\n",
    "                metadata, offset = 0, skip_qc = False):\n",
    "    \n",
    "    tf_matrix, dataset_ids = load_tf_matrix(config_key, old_data_path, original_num_bins, \n",
    "                                        metadata, offset = offset, skip_qc = skip_qc)\n",
    "    \n",
    "    projected_tf_matrix = data.project_sparse_matrix(tf_matrix.T, hits_binmap, len(data.genome))\n",
    "    \n",
    "    write_tf_matrix(data, technology, dataset_ids, projected_tf_matrix, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChIP-seq data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_tf_binding(data = data, technology = 'ChIP-seq', config_key = 'tf_chipseq', old_data_path = old_data_path, \n",
    "                  original_num_bins = len(old_genome_100bp), metadata = metadata, offset = 1, skip_qc = False,\n",
    "                  hits_binmap = hits_binmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motif data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_tf_binding(data = data, technology = 'Motifs', config_key = 'genome_100bp_motif_index99', old_data_path = old_data_path,\n",
    "                original_num_bins = len(old_genome_100bp), metadata = motif_meta, offset = 0, skip_qc = True,\n",
    "                hits_binmap = hits_binmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 100bp hits data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading gene info ...\n"
     ]
    }
   ],
   "source": [
    "fine_hitbin_data = data_interface.DataInterface(species, window_size=100, make_new=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_fine_binmap = np.array(old_genome_100bp.map_genomes(fine_hitbin_data.genome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_tf_binding(data = fine_hitbin_data, technology = 'ChIP-seq', config_key = 'tf_chipseq', old_data_path = old_data_path, \n",
    "                  original_num_bins = len(old_genome_100bp), metadata = metadata, offset = 1, skip_qc = False,\n",
    "                  hits_binmap = hits_fine_binmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_tf_binding(data = fine_hitbin_data, technology = 'Motifs', config_key = 'genome_100bp_motif_index99', old_data_path = old_data_path,\n",
    "                original_num_bins = len(old_genome_100bp), metadata = motif_meta, offset = 0, skip_qc = True,\n",
    "                hits_binmap = hits_fine_binmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motifs mapping correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, dataset_ids, metadata = fine_hitbin_data.get_binding_data('Motifs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_metadata = pd.DataFrame(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>factor</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M00082</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>Transfac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>MC00312</td>\n",
       "      <td>RUNX1</td>\n",
       "      <td>Cistrome</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sample_id factor    source\n",
       "3      M00082  RUNX1  Transfac\n",
       "283   MC00312  RUNX1  Cistrome"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_metadata[factor_metadata.factor == 'RUNX1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3]),)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(dataset_ids == 'M00082')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M00041', 'M00062', 'M00072', 'M00082', 'M00085'], dtype='<U7')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_conversion/runx1_motif_windows.bed', 'w') as f:\n",
    "    for ind in matrix[:, 3].tocoo().row[:1000]:\n",
    "        ind = int(ind)\n",
    "        print(fine_hitbin_data.genome.get_region(ind)[0], file = f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t3007900\t3008000\r\n",
      "chr1\t3047900\t3048000\r\n",
      "chr1\t3095500\t3095600\r\n",
      "chr1\t3120400\t3120500\r\n",
      "chr1\t3130600\t3130700\r\n",
      "chr1\t3134200\t3134300\r\n",
      "chr1\t3195700\t3195800\r\n",
      "chr1\t3212300\t3212400\r\n",
      "chr1\t3217000\t3217100\r\n",
      "chr1\t3219800\t3219900\r\n"
     ]
    }
   ],
   "source": [
    "!head data_conversion/runx1_motif_windows.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lisa_2.1_testing",
   "language": "python",
   "name": "lisa_2.1_testing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
