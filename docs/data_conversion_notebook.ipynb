{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "import importlib\n",
    "import seaborn as sns\n",
    "sns.set(style = 'ticks')\n",
    "import configparser\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin  docs  LICENSE  lisa  MANIFEST.in  README.md  setup.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls lisa2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp lisa2/lisa/gene_selection.py ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gene_selection import Gene, GeneSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define transformation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_geneset(config, species, genelist_h5, tad_data_file):\n",
    "    \n",
    "    with h5.File(genelist_h5, 'r') as data:\n",
    "        gene_list = data['RefSeq'][...].astype(str)\n",
    "    \n",
    "    all_genes = GeneSet()\n",
    "\n",
    "    for geneline in gene_list:\n",
    "        chrom, start, end, _id, symbol = geneline.split(':')\n",
    "        newgene = Gene(chrom, start, end, [symbol, _id])\n",
    "        all_genes.add_gene(newgene)\n",
    "        \n",
    "    tad_data = pd.read_csv(tad_data_file, sep = '\\t', encoding = 'latin')\n",
    "    tad_data['domain'] = (tad_data.k4me3_order_cluster.astype(str) + ',' + tad_data.tad_order_cluster.astype(str)).values\n",
    "    tad_domains = tad_data.set_index('geneName').domain\n",
    "        \n",
    "    for gene_name, tad_domain in tad_domains.items():\n",
    "        try:\n",
    "            for gene in all_genes.genes_by_name[gene_name]:\n",
    "                gene.tad_domain = tad_domain\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "    with open(config.get('genes','master_gene_list').format(package_path = './', species = species), 'w') as genelist:\n",
    "        genelist.write(str(all_genes))\n",
    "                \n",
    "    return all_genes\n",
    "\n",
    "def calc_rp_map(config, species, bin_regions_file, geneset):\n",
    "\n",
    "    bin_regions = pd.read_csv(bin_regions_file, sep = '\\t', header = None)\n",
    "    bin_regions.columns = ['chrom','start','end','bin_num']\n",
    "    bin_regions.bin_num -= 1\n",
    "    bin_groups = bin_regions.groupby('chrom')\n",
    "\n",
    "    loadingbar = utils.LoadingBar('Calculating RP matrix', len(geneset), length = 40)\n",
    "\n",
    "    indices, rp_vals, gene_locs = [],[],[]\n",
    "\n",
    "    for chrom, bins in bin_groups:\n",
    "        bin_intervals = np.concatenate([[0], bins.end.values])\n",
    "        genes_on_chrom = geneset.get_genes_by_chrom(chrom)\n",
    "        for gene in genes_on_chrom:\n",
    "            rp, bin_indices = gene.get_RP_signature(bin_intervals, bins.bin_num.values)\n",
    "            rp_vals.append(rp)\n",
    "            indices.append(bin_indices)\n",
    "            gene_locs.append(gene.get_location())\n",
    "            print('\\r', loadingbar, end = '')\n",
    "            \n",
    "    rp_map = utils.ragged_array_to_sparse_matrix(indices, rp_vals, \n",
    "                int(config.get('lisa_params','num_bins_{}'.format(species)))).transpose()\n",
    "    \n",
    "    sparse.save_npz(config.get('RP_map', 'matrix').format(package_path = './', species = species), rp_map)\n",
    "    \n",
    "    with open(config.get('genes','gene_locs').format(package_path = './', species = species), 'w') as f:\n",
    "        f.write('\\n'.join(gene_locs))\n",
    "    \n",
    "    return rp_map, gene_locs\n",
    "\n",
    "def read_metadata(metadata_file):\n",
    "    metadata = pd.read_csv(metadata_file, sep = '\\t', encoding = \"ISO-8859-1\").set_index('id')\n",
    "    metadata.index = metadata.index.astype(np.str)\n",
    "    \n",
    "    try:\n",
    "        metadata['qc']\n",
    "    except KeyError:\n",
    "        metadata['qc'] = 1\n",
    "        metadata['factor'] = metadata.index        \n",
    "        \n",
    "    return metadata\n",
    "\n",
    "def save_RP_matrix(h5_object, config, technology, bins_matrix, rp_map, gene_locs, dataset_ids):\n",
    "    \n",
    "    print('\\tCalculating RP matrix ...')\n",
    "    #genes x bins \\dot bins * datasets = genes * datasets\n",
    "    rp_matrix = rp_map.dot(bins_matrix)\n",
    "    \n",
    "    if isinstance(rp_matrix, (sparse.csr_matrix, sparse.csc_matrix)):\n",
    "        rp_matrix = np.array(rp_matrix.todense()).astype(np.float64)\n",
    "    \n",
    "    print('\\tSaving RP matrix ...')\n",
    "    \n",
    "    #del h5_object[config['accessibility_assay']['reg_potential_gene_locs'].format(technology = technology)]\n",
    "    h5_object.create_dataset(\n",
    "        config['accessibility_assay']['reg_potential_gene_locs'].format(technology = technology),\n",
    "        data = np.array(gene_locs).astype('S')\n",
    "    )\n",
    "    \n",
    "    #del h5_object[config['accessibility_assay']['reg_potential_dataset_ids'].format(technology = technology)]\n",
    "    h5_object.create_dataset(\n",
    "        config['accessibility_assay']['reg_potential_dataset_ids'].format(technology = technology),\n",
    "        data = np.array(dataset_ids).astype('S')\n",
    "    )\n",
    "    \n",
    "    #del h5_object[config['accessibility_assay']['reg_potential_matrix'].format(technology = technology)]\n",
    "    h5_object.create_dataset(\n",
    "        config['accessibility_assay']['reg_potential_matrix'].format(technology = technology),\n",
    "        data = rp_matrix\n",
    "    )\n",
    "\n",
    "def index_binned_reads(*,h5_save_file, config, technology, rp_map, gene_locs, binned_reads_h5_file, metadata_file):\n",
    "    \n",
    "    print('\\tReading metadata ...')\n",
    "    metadata = read_metadata(metadata_file)\n",
    "    qc_status = metadata.qc\n",
    "    \n",
    "    print('\\tReading binned reads data ...')\n",
    "\n",
    "    with h5.File(binned_reads_h5_file, 'r') as binned_reads:\n",
    "\n",
    "        dataset_ids = binned_reads['IDs'][...].astype(str)\n",
    "\n",
    "        dataset_subset = qc_status[dataset_ids].astype(np.bool).values\n",
    "\n",
    "        reads_matrix = binned_reads['OrderCount'][:, dataset_subset]\n",
    "        \n",
    "    dataset_ids = dataset_ids[dataset_subset]\n",
    "    \n",
    "    reads_matrix = reads_matrix\n",
    "    \n",
    "    num_reads = reads_matrix.sum(axis = 0)\n",
    "    \n",
    "    alpha = 2.0\n",
    "    bounds = (num_reads.mean() - alpha*num_reads.std(), num_reads.mean() + alpha*num_reads.std())\n",
    "\n",
    "    normal_samples = np.logical_and(bounds[0] <= num_reads, num_reads <= bounds[1])\n",
    "    \n",
    "    reads_matrix = reads_matrix[:,normal_samples]\n",
    "    dataset_ids = dataset_ids[normal_samples]\n",
    "    \n",
    "    reads_matrix = reads_matrix * 1e8 / reads_matrix.sum(axis = 0)\n",
    "    \n",
    "    dataset_ids = np.array([id_.split('_')[0] for id_ in dataset_ids])\n",
    "    \n",
    "    with h5.File(h5_save_file, 'a') as h5_object:\n",
    "    \n",
    "        save_RP_matrix(h5_object, config, technology, reads_matrix, rp_map, gene_locs, dataset_ids)\n",
    "\n",
    "        loading_bar = utils.LoadingBar('\\tWriting ID-indexed data', dataset_subset.sum(), 20)\n",
    "\n",
    "        for i, dataset_id in enumerate(dataset_ids):\n",
    "            print('\\r', loading_bar, end = '')\n",
    "            #del h5_object[config['accessibility_assay']['binned_reads'].format(technology = technology, dataset_id = dataset_id)]\n",
    "            try: \n",
    "                h5_object.create_dataset(\n",
    "                    config['accessibility_assay']['binned_reads'].format(technology = technology, dataset_id = dataset_id),\n",
    "                    data = reads_matrix[:, i]\n",
    "                )\n",
    "            except OSError as err:\n",
    "                print('Error saving dataset #{}: {}'.format(str(dataset_id), str(err)))\n",
    "\n",
    "def reformat_TF_hits(*,h5_save_file, config, species, technology, rp_map, gene_locs, factor_binding_h5, window_converter_file, metadata_file, offset = 0):\n",
    "    \n",
    "    print('\\tReading metadata ...')\n",
    "    metadata = read_metadata(metadata_file)\n",
    "    \n",
    "    window_converter = np.load(window_converter_file)\n",
    "    \n",
    "    with h5.File(factor_binding_h5, 'r') as tf_hits:\n",
    "\n",
    "        num_samples = len(list(tf_hits.keys()))\n",
    "        \n",
    "        loading_bar = utils.LoadingBar('\\tCollecting binding data', num_samples, 20)\n",
    "        \n",
    "        peak_list, values, dataset_ids = [],[],[]\n",
    "        \n",
    "        for sample in tf_hits.keys():\n",
    "            print('\\r',loading_bar, end = '')\n",
    "            \n",
    "            if not sample == 'IDs':\n",
    "                \n",
    "                try:\n",
    "                    sample_metadata = metadata.loc[str(sample)]\n",
    "                \n",
    "                    if sample_metadata.qc == 1:\n",
    "                        \n",
    "                        factor_name = sample_metadata.factor.replace('/', '-').replace('_','-')\n",
    "\n",
    "                        peaks = tf_hits[sample][...]\n",
    "                        peaks = window_converter[peaks - offset]\n",
    "                        \n",
    "                        peak_list.append(peaks)\n",
    "                        values.append(np.ones(len(peaks)))\n",
    "                        dataset_ids.append(sample)\n",
    "                        \n",
    "                except OSError:\n",
    "                    print('\\n\\tError saving data for sample {}, factor: {}'\\\n",
    "                          .format(str(sample), sample_metadata.factor))\n",
    "                except KeyError:\n",
    "                    print('\\n\\tError: No metadata for sample {}'.format(str(sample)))\n",
    "                    \n",
    "    tf_hits = utils.ragged_array_to_sparse_matrix(peak_list, values, \n",
    "                                int(config.get('lisa_params','num_bins_{}'.format(species))))\n",
    "    \n",
    "    with h5.File(h5_save_file, 'a') as h5_object:\n",
    "        save_RP_matrix(h5_object, config, technology, tf_hits, rp_map, gene_locs, dataset_ids)\n",
    "        \n",
    "    sparse.save_npz(config.get('factor_binding','matrix').format(package_path = './', species = species, technology = technology), tf_hits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-09-25 10:34:14--  http://lisa.cistrome.org/cistromedb_data/lisa_v1.2_mm10.tar.gz\n",
      "Resolving lisa.cistrome.org (lisa.cistrome.org)... 155.52.218.90\n",
      "Connecting to lisa.cistrome.org (lisa.cistrome.org)|155.52.218.90|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 21431746089 (20G) [application/x-gzip]\n",
      "Saving to: ‘lisa_v1.2_mm10.tar.gz’\n",
      "\n",
      "lisa_v1.2_mm10.tar. 100%[===================>]  19.96G   953MB/s    in 21s     \n",
      "\n",
      "2020-09-25 10:35:29 (954 MB/s) - ‘lisa_v1.2_mm10.tar.gz’ saved [21431746089/21431746089]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -c http://lisa.cistrome.org/cistromedb_data/lisa_v1.2_mm10.tar.gz\n",
    "\n",
    "!mv lisa_v1.2_mm10.tar.gz old_data/\n",
    "\n",
    "!tar -xvf old_data/lisa_v1.2_mm10.tar.gz\n",
    "\n",
    "!mv mm10/ old_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cistrome.txt\r\n",
      "cluster_mouse\r\n",
      "lisa_meta.xls\r\n",
      "margeRP_DNase_mm.h5\r\n",
      "margeRP_H3K27ac_mm.h5\r\n",
      "mm10_100to1000window.out.npy\r\n",
      "mm10_beta_peak5fold.h5\r\n",
      "mm10.genome\r\n",
      "mm10_lisa_tf_100bp_all_nonhm_nonca_peak5fold.h5\r\n",
      "mm10_marge2_motif_100bp_99.h5\r\n",
      "mm10_promoter_TADann_H3K4me3_enhance_k27me3_Using.xls\r\n",
      "mm10_tf_new_beta_rp.h5\r\n",
      "mm10.tss\r\n",
      "mm10_window1kb.bed\r\n",
      "mm10_window1kb_DNase.h5\r\n",
      "mm10_window1kb_H3K27ac.h5\r\n",
      "mm10_window1kb_tss.bed\r\n",
      "mm_tf_new_beta_rp.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls old_data/mm10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = h5.File('./old_data/mm10/mm_tf_new_beta_rp.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('./lisa2/lisa/config.ini')\n",
    "\n",
    "geneset = define_geneset(config, 'mm10', './old_data/mm10/cluster_mouse/DNase_median_for_each_cluster.h5', \n",
    "                        'old_data/mm10/mm10_promoter_TADann_H3K4me3_enhance_k27me3_Using.xls')\n",
    "\n",
    "rp_map, gene_locs = calc_rp_map(config, 'mm10', 'old_data/mm10/mm10_window1kb.bed', geneset)\n",
    "\n",
    "h5_name = 'lisa_data_mm10_reads_normalized.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5.File('data/mm10/' + h5_name, 'w') as data:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tReading metadata ...\n",
      "\tReading binned reads data ...\n",
      "\tCalculating RP matrix ...\n",
      "\tSaving RP matrix ...\n",
      " \tWriting ID-indexed data: [===================>]"
     ]
    }
   ],
   "source": [
    "index_binned_reads(h5_save_file = 'data/mm10/' + h5_name, config = config, technology = 'DNase', \n",
    "                   rp_map = rp_map, gene_locs = gene_locs, binned_reads_h5_file = './old_data/mm10/mm10_window1kb_DNase.h5',\n",
    "                   metadata_file = 'old_data/mm10/lisa_meta.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tReading metadata ...\n",
      "\tReading binned reads data ...\n",
      "\tCalculating RP matrix ...\n",
      "\tSaving RP matrix ...\n",
      " \tWriting ID-indexed data: [===============>    ]Error saving dataset #44619: Unable to create link (name already exists)\n",
      " \tWriting ID-indexed data: [===================>]"
     ]
    }
   ],
   "source": [
    "index_binned_reads(h5_save_file = 'data/mm10/' + h5_name, config = config, technology = 'H3K27ac', \n",
    "                   rp_map = rp_map, gene_locs = gene_locs, binned_reads_h5_file = './old_data/mm10/mm10_window1kb_H3K27ac.h5',\n",
    "                   metadata_file = 'old_data/mm10/lisa_meta.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tReading metadata ...\n",
      " \tCollecting binding data: [====================]\n",
      "\tCalculating RP matrix ...\n",
      "\tSaving RP matrix ...\n"
     ]
    }
   ],
   "source": [
    "reformat_TF_hits(h5_save_file = 'data/mm10/' + h5_name, config = config, species = 'mm10', technology = 'ChIP-seq',\n",
    "                 rp_map = rp_map, gene_locs = gene_locs, factor_binding_h5 = 'old_data/mm10/mm10_lisa_tf_100bp_all_nonhm_nonca_peak5fold.h5',\n",
    "                 window_converter_file = 'old_data/mm10/mm10_100to1000window.out.npy', \n",
    "                 metadata_file = 'old_data/mm10/lisa_meta.xls', offset = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tReading metadata ...\n",
      " \tCollecting binding data: [=================>  ]\n",
      "\tError: No metadata for sample TFs\n",
      " \tCollecting binding data: [====================]\n",
      "\tCalculating RP matrix ...\n",
      "\tSaving RP matrix ...\n"
     ]
    }
   ],
   "source": [
    "reformat_TF_hits(h5_save_file = 'data/mm10/' + h5_name, config = config, species = 'mm10', technology = 'Motifs',\n",
    "                 rp_map = rp_map, gene_locs = gene_locs, factor_binding_h5 = 'old_data/mm10/mm10_marge2_motif_100bp_99.h5',\n",
    "                 window_converter_file = 'old_data/mm10/mm10_100to1000window.out.npy', \n",
    "                 metadata_file = 'old_data/mm10/cistrome.txt', offset = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating Read Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = read_metadata('old_data/hg38/lisa_meta.xls')\n",
    "\n",
    "data = h5.File('./old_data/hg38/hg38_window1kb_DNase.h5' ,'r')\n",
    "\n",
    "dsid = data['IDs'][...].astype(str)\n",
    "\n",
    "ds_mask = m.qc[dsid].astype(np.bool)\n",
    "\n",
    "arr = data['OrderCount'][:, ds_mask.values]\n",
    "\n",
    "arr_sums = arr.sum(axis = 0)\n",
    "\n",
    "sns.distplot(arr_sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72740.716796875, 131616.580078125)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "selections = set(['3147',\n",
    " '45067',\n",
    " '40800',\n",
    " '44974',\n",
    " '44921',\n",
    " '44959',\n",
    " '3136',\n",
    " '58044',\n",
    " '41430',\n",
    " '3179'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 2.0\n",
    "bounds = (arr_sums.mean() - alpha*arr_sums.std(), arr_sums.mean() + alpha*arr_sums.std())\n",
    "\n",
    "outliers = ~np.logical_and(bounds[0] < arr_sums, arr_sums < bounds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3179', '58044'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selections.intersection(set(dsid[ds_mask][outliers]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species        Homo sapiens\n",
       "factor                DNase\n",
       "factor_type              ca\n",
       "cell_line               NaN\n",
       "cell_type               NaN\n",
       "tissue               Thymus\n",
       "qc                        1\n",
       "Name: 58044, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.loc['58044']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lisa_env",
   "language": "python",
   "name": "lisa_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
