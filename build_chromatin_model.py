
from sklearn.feature_selection import SelectKBest, f_classif
import numpy as np


#### ADD DATASET NORMALIZATION

def select_best_datasets_LR_model(reg_potential_data, labels, epsilon = 1e-7, num_datasets = 10, max_iters = 100, penalty_min = -1, penalty_max = 10):
    """
    Select the best n datasets discriminating between query and background genes. Use binary search to tune the regularization parameter of the L1 model. Increasing
    Regularization decreases the number of datasets used.

    epsilon: if a dataset's coefficient exceeds this value, count as selected dataset
    num_datasets: desired number of datasets selected
    max_iters: maximum iterations of binary search
    penalty_min: penalty of LR model defined as C = 2**-penalty, with decreasing C meaning increasing regularization. For penalty_min = -1, C = 2^(-1 * 1) = 2, so less regularized.
    penalty_max: penalty of LR model, for penalty_max = 10, C = 2^-10, a very regularized model

    returns:
    best_datasets: boolean index of datasets selected
    """
    


def select_best_datasets_ANOVA(reg_potential_data, labels, k_features = 200):
    """
    Use ANOVA feature selector to narrow the field before more expensive LR feature selection
    """
    assert( reg_potential_data.shape[1] <= k_features )

    selected = SelectKBest(f_classif, k=k_features).fit(reg_potential_data, labels).get_support()

    return selected

def build_chromatin_model(reg_potential_data, dataset_metadata, labels, sample_selection_model, chromatin_model, covariates = None, 
    num_anova_features = 200):
    """
    reg_potential_data: numpy matrix of gene x sample of RP data
    labels: generated by background_genes_selection.py, lables for each gene in query vs. background 
    chromatin_model: GridSearchCV sklearn model that trains a model to fit the chromatin landscape. Changes in the activation of this model show strength of effect of ISD
    sample_selection_model: strategy to find most discriminatory datasets
    num_anova_features: number of features to select using ANOVA
    num_LR_features: number of features to select using the Logistic Regression L1 model
    """
    assert( isinstance(reg_potential_data, np.array ) ), 'Regulatory potential data must be provided as numpy array'
    assert( isinstance(labels, np.array) ), 'Labels provided must be of type numpy array'
    assert( isinstance(dataset_metadata, list, np.array))
    assert( dataset_metadata.shape[0] == reg_potential_data.shape[0] and len(dataset_metadata.shape) == 1)

    dataset_metadata = np.array(dataset_metadata)

    #select features with anova
    anova_featues = select_best_datasets_ANOVA(reg_potential_data, labels, k_features = num_anova_features)

    #leave out worst features
    reg_potential_data = reg_potential_data[:, anova_featues]
    dataset_metadata = dataset_metadata[anova_featues]

    #select best features using LR, record some info about model
    sample_selection_model = sample_selection_model.fit(reg_potential_data, labels)
    selected_features = sample_selection_model.get_selected_datasets()

    #subset for best features
    reg_potential_data = reg_potential_data[:, selected_features] 
    dataset_metadata = dataset_metadata[selected_features]

    #add covariates back to data
    if not covariates is None:
        reg_potential_data = np.concatenate([reg_potential_data, covariates], axis = 1)

    #train chromatin landscape model
    chromatin_model.fit(reg_potential_data, labels, chromatin_model)

    #return final trained model, the selected features, and some model metadata
    return reg_potential_data, dataset_metadata, sample_selection_model, chromatin_model


